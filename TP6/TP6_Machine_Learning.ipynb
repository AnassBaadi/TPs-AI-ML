{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBY1Vdsp00eN"
      },
      "source": [
        "<center><h1> Corréction Série de Travaux Pratiques N° 6 - Machine Learning </h1></center>\n",
        "<center><h2> Regression Logistique</h2></center>\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xIqBKf-_MK9"
      },
      "source": [
        "# **Partie I : Regression Logistique**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OT_v-xSH8NW"
      },
      "source": [
        "Vous trouverez ci-joint un exemple d'utilisation d'algorithme de regréssion logistique avec les quatres étapes principales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "JhmrQYpLAkeD"
      },
      "outputs": [],
      "source": [
        "# Step 1: Import packages, functions\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Step 2: Get data\n",
        "x = np.arange(10).reshape(-1, 1)\n",
        "y = np.array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1])\n",
        "\n",
        "# Step 3: Create a model and train it\n",
        "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0, max_iter=100)\n",
        "model.fit(x, y)\n",
        "\n",
        "# Step 4: Evaluate the model\n",
        "p_pred = model.predict_proba(x) #prediction de probabilite de chaque classe ex:p_pred: [[0.81999686 0.18000314] 1ere pour classe 0 et 2eme pour classe 1\n",
        "y_pred = model.predict(x)\n",
        "score_ = model.score(x, y)\n",
        "conf_m = confusion_matrix(y, y_pred)\n",
        "report = classification_report(y, y_pred) #accuracy= Nb Prediction Vraies/Nb total Vrai . Nb d'exemples dataset\n",
        "#precision= Nb PredVraie/Nb Prediction Totale "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl6j49CVBPZy",
        "outputId": "1fbd1535-bc83-4900-ad7d-5282b5b93143"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x: [[0]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [5]\n",
            " [6]\n",
            " [7]\n",
            " [8]\n",
            " [9]]\n",
            "y: [0 1 0 0 1 1 1 1 1 1]\n",
            "intercept: [-1.51632619]\n",
            "coef: [[0.703457]]\n",
            "p_pred: [[0.81999686 0.18000314]\n",
            " [0.69272057 0.30727943]\n",
            " [0.52732579 0.47267421]\n",
            " [0.35570732 0.64429268]\n",
            " [0.21458576 0.78541424]\n",
            " [0.11910229 0.88089771]\n",
            " [0.06271329 0.93728671]\n",
            " [0.03205032 0.96794968]\n",
            " [0.0161218  0.9838782 ]\n",
            " [0.00804372 0.99195628]]\n",
            "y_pred: [0 0 0 1 1 1 1 1 1 1]\n",
            "score_: 0.8\n",
            "conf_m: [[2 1]\n",
            " [1 6]]\n",
            "report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.67      0.67         3\n",
            "           1       0.86      0.86      0.86         7\n",
            "\n",
            "    accuracy                           0.80        10\n",
            "   macro avg       0.76      0.76      0.76        10\n",
            "weighted avg       0.80      0.80      0.80        10\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('x:', x)\n",
        "print('y:', y)\n",
        "print('intercept:', model.intercept_)\n",
        "print('coef:', model.coef_)\n",
        "print('p_pred:', p_pred)\n",
        "print('y_pred:', y_pred)\n",
        "print('score_:', score_)\n",
        "print('conf_m:', conf_m)\n",
        "print('report:', report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CRPgzmJAP9p"
      },
      "source": [
        "# **Partie II : Classification Binaire**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifx0Fkf3QfMe"
      },
      "source": [
        "L'objectif de l'ensemble de données \"**diabetes.csv**\" est de prédire, sur la base de mesures diagnostiques, si un patient **souffre de diabète ou pas**.\n",
        "\n",
        "Ce dataset contient les caractéristiques suivants\n",
        "\n",
        "**Grossesses**: Nombre de fois enceintes.\n",
        "\n",
        "**Glucose**: concentration plasmatique de glucose à 2 heures lors d'un test oral de tolérance au glucose.\n",
        "\n",
        "**Pression artérielle** : tension artérielle diastolique (mm Hg).\n",
        "\n",
        "**Épaisseur de la peau** : épaisseur du pli cutané du triceps (mm).\n",
        "\n",
        "**Insuline** : insuline sérique de 2 heures (mu U/ml).\n",
        "\n",
        "**IMC** : Indice de masse corporelle (poids en kg/(taille en m)^2).\n",
        "\n",
        "**DiabetesPedigreeFunction** : fonction généalogique du diabète.\n",
        "\n",
        "**Âge** : Âge (ans).\n",
        "\n",
        "**Résultat** : variable de classe (0 ou 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFizXutMLhX1"
      },
      "source": [
        "### **Questions :**\n",
        "\n",
        "Étape 1 : Importer et afficher et explorer l'ensemble de données \"**diabetes.csv**\"\n",
        "\n",
        "Étape 2 : Créer dépendante d'une variable indépendante et stockée sur les variables X et Y.\n",
        "\n",
        "Étape 3 : Transformer les chaînes en entier.\n",
        "\n",
        "Étape 4 : Divisez les données en ensembles d'entrainement et de test.\n",
        "\n",
        "Étape 5 : Définir l'algorithme de régression logistique.\n",
        "\n",
        "Étape 6 :Tester les données de test en utilisant votre modèle.\n",
        "\n",
        "Étape 7 : Évaluation du modèle.\n",
        "\n",
        "Étape 8 : Prédire avec de nouvelles valeurs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy :79.69%\n",
            "Confusion Matrix\n",
            "[[114  14]\n",
            " [ 25  39]]\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.89      0.85       128\n",
            "           1       0.74      0.61      0.67        64\n",
            "\n",
            "    accuracy                           0.80       192\n",
            "   macro avg       0.78      0.75      0.76       192\n",
            "weighted avg       0.79      0.80      0.79       192\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Binary Classification : Diabetes\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "diab=pd.read_csv(\"diabetes.csv\")\n",
        "X=diab.iloc[:,:-1]\n",
        "y=diab.iloc[:,-1] \n",
        "\n",
        "\n",
        "#Étape 4 : Divisez les données en ensembles d'entrainement et de test.\n",
        "X_train, X_test, y_train, y_test =train_test_split(X,y,random_state=104,test_size=0.25,shuffle=True)\n",
        "\n",
        "#Étape 5 : Définir l'algorithme de régression logistique.\n",
        "model=LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "#Étape 6 :Tester les données de test en utilisant votre modèle.\n",
        "y_pred=model.predict(X_test)\n",
        "accuracy=accuracy_score(y_test,y_pred) #+ accu ==> max iter ++ et train_size++ et penalisation(regularization )\n",
        "conf_matrix=confusion_matrix(y_test,y_pred)\n",
        "class_report= classification_report(y_test,y_pred)\n",
        "print(f\"Accuracy :{accuracy*100:.2f}%\")\n",
        "print(\"Confusion Matrix\")\n",
        "print(conf_matrix)\n",
        "print(\"classification report\")\n",
        "print(class_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wlRBxy0D99y",
        "outputId": "cefe284a-c332-46d5-8dd8-cb6ab624d608"
      },
      "outputs": [],
      "source": [
        " # Se connecter\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0NC3rVjEMTt",
        "outputId": "c99b0f4b-e00b-4002-b048-7794de9c3307"
      },
      "outputs": [],
      "source": [
        "# cd drive/My Drive/Colab Notebooks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3Zbjz_AAZ5l"
      },
      "source": [
        "# **Partie II : Classification Multi-Classe**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1NijNx4OpVg"
      },
      "source": [
        "Pour cette partie, on utilisera le **dataset IRIS**. Ce dernier est une base de données regroupant les caractéristiques de **trois espèces de fleurs d’Iris, à savoir Setosa, Versicolour et Virginica**. Chaque ligne de ce jeu de données est une observation des caractéristiques d’une fleur d’Iris. Ce dataset décrit les espèces d’Iris par quatre propriétés : longueur et largeur de sépales ainsi que longueur et largeur de pétales. La base de données comporte 150 observations (50 observations par espèce)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSTbiW8UMiPt"
      },
      "source": [
        "### **Questions :**\n",
        "\n",
        "Étape 1 : Importer, afficher et explorer l'ensemble de données \"**iris.csv**\"\n",
        "\n",
        "Étape 2 : Créer dépendante d'une variable indépendante et stockée sur les variables X et Y.\n",
        "\n",
        "Étape 3 : Transformer les chaînes en entier.\n",
        "\n",
        "Étape 4 : Divisez les données en ensembles d'entrainement et de test.\n",
        "\n",
        "Étape 5 : Définir l'algorithme de régression logistique.\n",
        "\n",
        "Étape 6 :Tester les données de test en utilisant votre modèle.\n",
        "\n",
        "Étape 7 : Évaluation du modèle.\n",
        "\n",
        "Étape 8 : Prédire avec de nouvelles valeurs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "P8PUWA4oTlBB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy :100.00%\n",
            "Confusion Matrix\n",
            "[[10  0  0]\n",
            " [ 0 17  0]\n",
            " [ 0  0 11]]\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00        17\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        38\n",
            "   macro avg       1.00      1.00      1.00        38\n",
            "weighted avg       1.00      1.00      1.00        38\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Multi-Class Classification : IRIS Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder as le\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "data_iris=pd.read_csv(\"iris.csv\")\n",
        "data_iris.head()\n",
        "\n",
        "x1=data_iris.drop([\"variety\"], axis=1)\n",
        "y1=data_iris[\"variety\"]\n",
        "x1.head()\n",
        "\n",
        "y1=le().fit_transform(y1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x1,y1,random_state=101, test_size=0.25, shuffle=True)\n",
        "\n",
        "model=LogisticRegression(max_iter=100)\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "y_pred=model.predict(X_test)\n",
        "accuracy=accuracy_score(y_test,y_pred)\n",
        "conf_matrix=confusion_matrix(y_test,y_pred)\n",
        "class_report= classification_report(y_test,y_pred)\n",
        "print(f\"Accuracy :{accuracy*100:.2f}%\")\n",
        "print(\"Confusion Matrix\")\n",
        "print(conf_matrix)\n",
        "print(\"classification report\")\n",
        "print(class_report)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
