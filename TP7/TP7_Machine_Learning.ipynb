{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBY1Vdsp00eN"
      },
      "source": [
        "<center><h1> Série de Travaux Pratiques N° 7 - Machine Learning </h1></center>\n",
        "<center><h2> K-Nearest Neighbor and Decision Tree</h2></center>\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OT_v-xSH8NW"
      },
      "source": [
        "Pour ce TP, on utilisera le **dataset IRIS**. Ce dernier est une base de données regroupant les caractéristiques de **trois espèces de fleurs d’Iris, à savoir Setosa, Versicolour et Virginica**. Chaque ligne de ce jeu de données est une observation des caractéristiques d’une fleur d’Iris. Ce dataset décrit les espèces d’Iris par quatre propriétés : longueur et largeur de sépales ainsi que longueur et largeur de pétales. La base de données comporte 150 observations (50 observations par espèce)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xIqBKf-_MK9"
      },
      "source": [
        "# **Partie I : K-Nearest Neighbor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG-mqDhouw_G"
      },
      "source": [
        "# **Questions :**\n",
        "\n",
        "1- Importer les packages nécessaires\n",
        "\n",
        "2- Lire l'ensemble de données dans le dataframe pandas\n",
        "\n",
        "3- Afficher et explorer l'ensemble de données \"**iris.csv**\"\n",
        "\n",
        "4- Extraire les variables d'entrée X\n",
        "\n",
        "5- Extraire les variables de sortie y\n",
        "\n",
        "6- Diviser le dataset en Train / Test\n",
        "\n",
        "7- Mise à l'échelle des fonctionnalités avec Transform()\n",
        "\n",
        "8- Définir votre modèle **KNN**\n",
        "\n",
        "9- Entraîner le modèle\n",
        "\n",
        "10- Prédiction sur l'ensemble de test\n",
        "\n",
        "11- Évaluation du modèle à l'aide de métriques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ab1P8GZVw4gj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   sepal.length  sepal.width  petal.length  petal.width variety\n",
            "0           5.1          3.5           1.4          0.2  Setosa\n",
            "1           4.9          3.0           1.4          0.2  Setosa\n",
            "2           4.7          3.2           1.3          0.2  Setosa\n",
            "3           4.6          3.1           1.5          0.2  Setosa\n",
            "4           5.0          3.6           1.4          0.2  Setosa\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal.length  150 non-null    float64\n",
            " 1   sepal.width   150 non-null    float64\n",
            " 2   petal.length  150 non-null    float64\n",
            " 3   petal.width   150 non-null    float64\n",
            " 4   variety       150 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 6.0+ KB\n",
            "None\n",
            "Accuracy :97.78%\n",
            "Confusion Matrix\n",
            "[[20  0  0]\n",
            " [ 0 17  0]\n",
            " [ 0  1  7]]\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Setosa       1.00      1.00      1.00        20\n",
            "  Versicolor       0.94      1.00      0.97        17\n",
            "   Virginica       1.00      0.88      0.93         8\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.98      0.96      0.97        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# IRIS Dataset : KNN\n",
        "\n",
        "\n",
        "# 1- Importer les packages nécessaires\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 2- Lire l'ensemble de données dans le dataframe pandas\n",
        "dataknn=pd.read_csv(\"iris.csv\")\n",
        "\n",
        "# 3- Afficher et explorer l'ensemble de données \"**iris.csv**\"\n",
        "print(dataknn.head())\n",
        "print(dataknn.info())\n",
        "\n",
        "# 4- Extraire les variables d'entrée X\n",
        "X=dataknn.drop('variety', axis=1)    #X=dataknn.iloc[:,:-1] \n",
        "\n",
        "# 5- Extraire les variables de sortie y\n",
        "y=dataknn['variety']                #y=dataknn.iloc[:,-1]\n",
        "\n",
        "# 6- Diviser le dataset en Train / Test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test =train_test_split(X,y,random_state=104,test_size=0.3,shuffle=True)\n",
        "\n",
        "# 7- Mise à l'échelle des fonctionnalités avec Transform()\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train =scaler.transform(X_train)\n",
        "X_test =scaler.transform(X_test)\n",
        "\n",
        "# 8- Définir votre modèle KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier= KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# 9- Entraîner le modèle\n",
        "classifier.fit(X_train,y_train)\n",
        "\n",
        "# 10- Prédiction sur l'ensemble de test\n",
        "y_pred= classifier.predict(X_test)\n",
        "\n",
        "# 11- Évaluation du modèle à l'aide de métriques\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "y_pred=classifier.predict(X_test)\n",
        "accuracy=accuracy_score(y_test,y_pred)\n",
        "conf_matrix=confusion_matrix(y_test,y_pred)\n",
        "class_report= classification_report(y_test,y_pred)\n",
        "print(f\"Accuracy :{accuracy*100:.2f}%\")\n",
        "print(\"Confusion Matrix\")\n",
        "print(conf_matrix)\n",
        "print(\"classification report\")\n",
        "print(class_report)\n",
        "\n",
        "#12- Changer le K = {5, 10, 20, 30, 40}, que remarquez-vous?\n",
        "#l'accuracy change avec la variation de K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRAn-qhBwqgp"
      },
      "source": [
        "# **Partie II : Decision Trees**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU1ELn91wg2R"
      },
      "source": [
        "# **Questions :**\n",
        "\n",
        "1- Importer les packages nécessaires\n",
        "\n",
        "2- Lire l'ensemble de données dans le dataframe pandas\n",
        "\n",
        "3- Afficher et explorer l'ensemble de données \"**iris.csv**\"\n",
        "\n",
        "4- Extraire les variables d'entrée X\n",
        "\n",
        "5- Extraire les variables de sortie y\n",
        "\n",
        "6- Diviser le dataset en Train / Test\n",
        "\n",
        "7- Mise à l'échelle des fonctionnalités avec Transform()\n",
        "\n",
        "8- Définir votre modèle **Decision Tree**\n",
        "\n",
        "9- Entraîner le modèle\n",
        "\n",
        "10- Prédiction sur l'ensemble de test\n",
        "\n",
        "11- Évaluation du modèle à l'aide de métriques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EfkJv-sMxI-c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy :95.56%\n",
            "Confusion Matrix\n",
            "[[15  0  0]\n",
            " [ 0 18  2]\n",
            " [ 0  0 10]]\n",
            "classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Setosa       1.00      1.00      1.00        15\n",
            "  Versicolor       1.00      0.90      0.95        20\n",
            "   Virginica       0.83      1.00      0.91        10\n",
            "\n",
            "    accuracy                           0.96        45\n",
            "   macro avg       0.94      0.97      0.95        45\n",
            "weighted avg       0.96      0.96      0.96        45\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# IRIS Dataset : Decision Tree\n",
        "\n",
        "\n",
        "# 1- Importer les packages nécessaires\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 2- Lire l'ensemble de données dans le dataframe pandas\n",
        "datadt=pd.read_csv(\"iris.csv\")\n",
        "\n",
        "# 3- Afficher et explorer l'ensemble de données \"iris.csv\"\n",
        "datadt.head()\n",
        "\n",
        "# 4- Extraire les variables d'entrée X\n",
        "X=datadt.drop('variety', axis=1)\n",
        "\n",
        "# 5- Extraire les variables de sortie y\n",
        "y=datadt['variety']\n",
        "\n",
        "# 6- Diviser le dataset en Train / Test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_dt, X_test_dt, y_train_dt, y_test_dt =train_test_split(X,y,random_state=420,test_size=0.3,shuffle=True)\n",
        "\n",
        "# 7- Mise à l'échelle des fonctionnalités avec Transform()\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "scaler.fit(X_train_dt)\n",
        "X_train_dt =scaler.transform(X_train_dt)\n",
        "X_test_dt =scaler.transform(X_test_dt)\n",
        "\n",
        "# 8- Définir votre modèle Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt=DecisionTreeClassifier()\n",
        "\n",
        "# 9- Entraîner le modèle\n",
        "dt.fit(X_train_dt,y_train_dt)\n",
        "\n",
        "# 10- Prédiction sur l'ensemble de test\n",
        "y_pred_dt=dt.predict(X_test_dt)\n",
        "\n",
        "# 11- Évaluation du modèle à l'aide de métriques\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "accuracy_dt=accuracy_score(y_test_dt,y_pred_dt)\n",
        "conf_matrix_dt=confusion_matrix(y_test_dt,y_pred_dt)\n",
        "class_report_dt= classification_report(y_test_dt,y_pred_dt)\n",
        "print(f\"Accuracy :{accuracy_dt*100:.2f}%\")\n",
        "print(\"Confusion Matrix\")\n",
        "print(conf_matrix_dt)\n",
        "print(\"classification report\")\n",
        "print(class_report_dt)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
